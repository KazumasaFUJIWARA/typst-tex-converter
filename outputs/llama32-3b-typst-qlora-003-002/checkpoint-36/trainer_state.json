{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 12.0,
  "eval_steps": 500,
  "global_step": 36,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 1.6679209992289543,
      "epoch": 0.37209302325581395,
      "grad_norm": 2.450902223587036,
      "learning_rate": 0.0,
      "loss": 1.0019,
      "mean_token_accuracy": 0.8097846880555153,
      "num_tokens": 1968.0,
      "step": 1
    },
    {
      "entropy": 1.3886689879000187,
      "epoch": 0.7441860465116279,
      "grad_norm": 2.480457305908203,
      "learning_rate": 2.5e-06,
      "loss": 1.0448,
      "mean_token_accuracy": 0.8093724586069584,
      "num_tokens": 5029.0,
      "step": 2
    },
    {
      "entropy": 1.5279894525354558,
      "epoch": 1.0,
      "grad_norm": 3.0176987648010254,
      "learning_rate": 5e-06,
      "loss": 1.0963,
      "mean_token_accuracy": 0.8274629007686268,
      "num_tokens": 6318.0,
      "step": 3
    },
    {
      "entropy": 1.662413202226162,
      "epoch": 1.372093023255814,
      "grad_norm": 3.3491013050079346,
      "learning_rate": 7.500000000000001e-06,
      "loss": 1.2099,
      "mean_token_accuracy": 0.7986961454153061,
      "num_tokens": 8014.0,
      "step": 4
    },
    {
      "entropy": 1.3560837619006634,
      "epoch": 1.744186046511628,
      "grad_norm": 2.215109348297119,
      "learning_rate": 1e-05,
      "loss": 1.0111,
      "mean_token_accuracy": 0.824311900883913,
      "num_tokens": 11175.0,
      "step": 5
    },
    {
      "entropy": 1.589459316297011,
      "epoch": 2.0,
      "grad_norm": 2.152785062789917,
      "learning_rate": 9.975923633360985e-06,
      "loss": 0.8327,
      "mean_token_accuracy": 0.8517454103990034,
      "num_tokens": 12636.0,
      "step": 6
    },
    {
      "entropy": 1.5222299359738827,
      "epoch": 2.3720930232558137,
      "grad_norm": 2.356004476547241,
      "learning_rate": 9.903926402016153e-06,
      "loss": 0.9871,
      "mean_token_accuracy": 0.839100543409586,
      "num_tokens": 14723.0,
      "step": 7
    },
    {
      "entropy": 1.5124020278453827,
      "epoch": 2.744186046511628,
      "grad_norm": 2.8367760181427,
      "learning_rate": 9.784701678661045e-06,
      "loss": 1.0356,
      "mean_token_accuracy": 0.8221327364444733,
      "num_tokens": 17027.0,
      "step": 8
    },
    {
      "entropy": 1.5811418674208901,
      "epoch": 3.0,
      "grad_norm": 1.6054368019104004,
      "learning_rate": 9.619397662556434e-06,
      "loss": 0.8293,
      "mean_token_accuracy": 0.8222464431415905,
      "num_tokens": 18954.0,
      "step": 9
    },
    {
      "entropy": 1.518830068409443,
      "epoch": 3.3720930232558137,
      "grad_norm": 1.9126653671264648,
      "learning_rate": 9.409606321741776e-06,
      "loss": 0.9054,
      "mean_token_accuracy": 0.8265761323273182,
      "num_tokens": 21674.0,
      "step": 10
    },
    {
      "entropy": 1.6357714012265205,
      "epoch": 3.744186046511628,
      "grad_norm": 2.3444552421569824,
      "learning_rate": 9.157348061512728e-06,
      "loss": 0.8404,
      "mean_token_accuracy": 0.848803736269474,
      "num_tokens": 23385.0,
      "step": 11
    },
    {
      "entropy": 1.4215910217978738,
      "epoch": 4.0,
      "grad_norm": 2.2420644760131836,
      "learning_rate": 8.865052266813686e-06,
      "loss": 0.9184,
      "mean_token_accuracy": 0.8257753361355175,
      "num_tokens": 25272.0,
      "step": 12
    },
    {
      "entropy": 1.451755452901125,
      "epoch": 4.372093023255814,
      "grad_norm": 1.9177298545837402,
      "learning_rate": 8.535533905932739e-06,
      "loss": 0.8803,
      "mean_token_accuracy": 0.8229151703417301,
      "num_tokens": 28245.0,
      "step": 13
    },
    {
      "entropy": 1.580625381320715,
      "epoch": 4.7441860465116275,
      "grad_norm": 2.363062620162964,
      "learning_rate": 8.171966420818227e-06,
      "loss": 0.8435,
      "mean_token_accuracy": 0.8271992728114128,
      "num_tokens": 30283.0,
      "step": 14
    },
    {
      "entropy": 1.6151537028225986,
      "epoch": 5.0,
      "grad_norm": 2.1249783039093018,
      "learning_rate": 7.777851165098012e-06,
      "loss": 0.7499,
      "mean_token_accuracy": 0.8610499772158536,
      "num_tokens": 31590.0,
      "step": 15
    },
    {
      "entropy": 1.6365783959627151,
      "epoch": 5.372093023255814,
      "grad_norm": 2.536555051803589,
      "learning_rate": 7.3569836841299905e-06,
      "loss": 0.8761,
      "mean_token_accuracy": 0.8326461352407932,
      "num_tokens": 33360.0,
      "step": 16
    },
    {
      "entropy": 1.4182224795222282,
      "epoch": 5.7441860465116275,
      "grad_norm": 1.6029719114303589,
      "learning_rate": 6.913417161825449e-06,
      "loss": 0.7483,
      "mean_token_accuracy": 0.8493253327906132,
      "num_tokens": 36519.0,
      "step": 17
    },
    {
      "entropy": 1.5970922383395108,
      "epoch": 6.0,
      "grad_norm": 2.433889389038086,
      "learning_rate": 6.451423386272312e-06,
      "loss": 0.807,
      "mean_token_accuracy": 0.8347415707328103,
      "num_tokens": 37908.0,
      "step": 18
    },
    {
      "entropy": 1.4846229776740074,
      "epoch": 6.372093023255814,
      "grad_norm": 1.872286081314087,
      "learning_rate": 5.975451610080643e-06,
      "loss": 0.7349,
      "mean_token_accuracy": 0.8364202082157135,
      "num_tokens": 40619.0,
      "step": 19
    },
    {
      "entropy": 1.552746120840311,
      "epoch": 6.7441860465116275,
      "grad_norm": 2.0534353256225586,
      "learning_rate": 5.490085701647805e-06,
      "loss": 0.7763,
      "mean_token_accuracy": 0.8578777946531773,
      "num_tokens": 43042.0,
      "step": 20
    },
    {
      "entropy": 1.633952108296481,
      "epoch": 7.0,
      "grad_norm": 2.3615403175354004,
      "learning_rate": 5e-06,
      "loss": 0.7457,
      "mean_token_accuracy": 0.8431747393174605,
      "num_tokens": 44226.0,
      "step": 21
    },
    {
      "entropy": 1.5348168350756168,
      "epoch": 7.372093023255814,
      "grad_norm": 1.7429503202438354,
      "learning_rate": 4.509914298352197e-06,
      "loss": 0.6615,
      "mean_token_accuracy": 0.879493422806263,
      "num_tokens": 46461.0,
      "step": 22
    },
    {
      "entropy": 1.5383450128138065,
      "epoch": 7.7441860465116275,
      "grad_norm": 1.674381971359253,
      "learning_rate": 4.02454838991936e-06,
      "loss": 0.7283,
      "mean_token_accuracy": 0.8506270721554756,
      "num_tokens": 49072.0,
      "step": 23
    },
    {
      "entropy": 1.5884887305173008,
      "epoch": 8.0,
      "grad_norm": 2.4620683193206787,
      "learning_rate": 3.5485766137276894e-06,
      "loss": 0.803,
      "mean_token_accuracy": 0.8197326822714373,
      "num_tokens": 50544.0,
      "step": 24
    },
    {
      "entropy": 1.4495652429759502,
      "epoch": 8.372093023255815,
      "grad_norm": 2.007430076599121,
      "learning_rate": 3.0865828381745515e-06,
      "loss": 0.7537,
      "mean_token_accuracy": 0.8304522782564163,
      "num_tokens": 53147.0,
      "step": 25
    },
    {
      "entropy": 1.6073604747653008,
      "epoch": 8.744186046511627,
      "grad_norm": 1.8363037109375,
      "learning_rate": 2.6430163158700116e-06,
      "loss": 0.6947,
      "mean_token_accuracy": 0.8688659891486168,
      "num_tokens": 55190.0,
      "step": 26
    },
    {
      "entropy": 1.6153841506351123,
      "epoch": 9.0,
      "grad_norm": 1.6988929510116577,
      "learning_rate": 2.2221488349019903e-06,
      "loss": 0.6217,
      "mean_token_accuracy": 0.8961980397051031,
      "num_tokens": 56862.0,
      "step": 27
    },
    {
      "entropy": 1.5560480579733849,
      "epoch": 9.372093023255815,
      "grad_norm": 1.5949705839157104,
      "learning_rate": 1.8280335791817733e-06,
      "loss": 0.6388,
      "mean_token_accuracy": 0.8687282167375088,
      "num_tokens": 59543.0,
      "step": 28
    },
    {
      "entropy": 1.597403671592474,
      "epoch": 9.744186046511627,
      "grad_norm": 2.0828301906585693,
      "learning_rate": 1.4644660940672628e-06,
      "loss": 0.7112,
      "mean_token_accuracy": 0.8532840460538864,
      "num_tokens": 61573.0,
      "step": 29
    },
    {
      "entropy": 1.477042024785822,
      "epoch": 10.0,
      "grad_norm": 1.9526242017745972,
      "learning_rate": 1.134947733186315e-06,
      "loss": 0.7456,
      "mean_token_accuracy": 0.874923207543113,
      "num_tokens": 63180.0,
      "step": 30
    },
    {
      "entropy": 1.5524442121386528,
      "epoch": 10.372093023255815,
      "grad_norm": 2.133892059326172,
      "learning_rate": 8.426519384872733e-07,
      "loss": 0.7746,
      "mean_token_accuracy": 0.8693882115185261,
      "num_tokens": 65326.0,
      "step": 31
    },
    {
      "entropy": 1.4911327995359898,
      "epoch": 10.744186046511627,
      "grad_norm": 1.5493525266647339,
      "learning_rate": 5.903936782582253e-07,
      "loss": 0.6127,
      "mean_token_accuracy": 0.8656345643103123,
      "num_tokens": 67813.0,
      "step": 32
    },
    {
      "entropy": 1.6337862665002996,
      "epoch": 11.0,
      "grad_norm": 1.5976914167404175,
      "learning_rate": 3.8060233744356634e-07,
      "loss": 0.6716,
      "mean_token_accuracy": 0.8595247377048839,
      "num_tokens": 69498.0,
      "step": 33
    },
    {
      "entropy": 1.598825380206108,
      "epoch": 11.372093023255815,
      "grad_norm": 1.9854949712753296,
      "learning_rate": 2.152983213389559e-07,
      "loss": 0.7016,
      "mean_token_accuracy": 0.8598572909832001,
      "num_tokens": 71308.0,
      "step": 34
    },
    {
      "entropy": 1.6593494899570942,
      "epoch": 11.744186046511627,
      "grad_norm": 1.8912359476089478,
      "learning_rate": 9.607359798384785e-08,
      "loss": 0.6796,
      "mean_token_accuracy": 0.8871787488460541,
      "num_tokens": 73415.0,
      "step": 35
    },
    {
      "entropy": 1.325485500422391,
      "epoch": 12.0,
      "grad_norm": 1.6967980861663818,
      "learning_rate": 2.4076366639015914e-08,
      "loss": 0.6587,
      "mean_token_accuracy": 0.8365102356130426,
      "num_tokens": 75816.0,
      "step": 36
    }
  ],
  "logging_steps": 1,
  "max_steps": 36,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 12,
  "save_steps": 1,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1287767051550720.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
