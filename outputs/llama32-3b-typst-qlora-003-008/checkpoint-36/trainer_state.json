{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 12.0,
  "eval_steps": 500,
  "global_step": 36,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "entropy": 1.6678120717406273,
      "epoch": 0.37209302325581395,
      "grad_norm": 2.386012315750122,
      "learning_rate": 0.0,
      "loss": 1.002,
      "mean_token_accuracy": 0.8103914856910706,
      "num_tokens": 1968.0,
      "step": 1
    },
    {
      "entropy": 1.3884074874222279,
      "epoch": 0.7441860465116279,
      "grad_norm": 2.4037837982177734,
      "learning_rate": 2.5e-06,
      "loss": 1.0445,
      "mean_token_accuracy": 0.8093724586069584,
      "num_tokens": 5029.0,
      "step": 2
    },
    {
      "entropy": 1.5278582031076604,
      "epoch": 1.0,
      "grad_norm": 2.9695520401000977,
      "learning_rate": 5e-06,
      "loss": 1.0964,
      "mean_token_accuracy": 0.8274629007686268,
      "num_tokens": 6318.0,
      "step": 3
    },
    {
      "entropy": 1.6622062027454376,
      "epoch": 1.372093023255814,
      "grad_norm": 3.2514638900756836,
      "learning_rate": 7.500000000000001e-06,
      "loss": 1.2099,
      "mean_token_accuracy": 0.7986961454153061,
      "num_tokens": 8014.0,
      "step": 4
    },
    {
      "entropy": 1.3559885881841183,
      "epoch": 1.744186046511628,
      "grad_norm": 2.1543750762939453,
      "learning_rate": 1e-05,
      "loss": 1.0109,
      "mean_token_accuracy": 0.824311900883913,
      "num_tokens": 11175.0,
      "step": 5
    },
    {
      "entropy": 1.589502383362163,
      "epoch": 2.0,
      "grad_norm": 2.1051833629608154,
      "learning_rate": 9.975923633360985e-06,
      "loss": 0.8323,
      "mean_token_accuracy": 0.8517454103990034,
      "num_tokens": 12636.0,
      "step": 6
    },
    {
      "entropy": 1.5223053693771362,
      "epoch": 2.3720930232558137,
      "grad_norm": 2.3008551597595215,
      "learning_rate": 9.903926402016153e-06,
      "loss": 0.9866,
      "mean_token_accuracy": 0.839100543409586,
      "num_tokens": 14723.0,
      "step": 7
    },
    {
      "entropy": 1.5123180635273457,
      "epoch": 2.744186046511628,
      "grad_norm": 2.7579479217529297,
      "learning_rate": 9.784701678661045e-06,
      "loss": 1.0358,
      "mean_token_accuracy": 0.8221327364444733,
      "num_tokens": 17027.0,
      "step": 8
    },
    {
      "entropy": 1.5811975869265469,
      "epoch": 3.0,
      "grad_norm": 1.5702319145202637,
      "learning_rate": 9.619397662556434e-06,
      "loss": 0.8285,
      "mean_token_accuracy": 0.8222464431415905,
      "num_tokens": 18954.0,
      "step": 9
    },
    {
      "entropy": 1.5188702829182148,
      "epoch": 3.3720930232558137,
      "grad_norm": 1.8812124729156494,
      "learning_rate": 9.409606321741776e-06,
      "loss": 0.9043,
      "mean_token_accuracy": 0.8265761323273182,
      "num_tokens": 21674.0,
      "step": 10
    },
    {
      "entropy": 1.6356830187141895,
      "epoch": 3.744186046511628,
      "grad_norm": 2.2950439453125,
      "learning_rate": 9.157348061512728e-06,
      "loss": 0.8397,
      "mean_token_accuracy": 0.848803736269474,
      "num_tokens": 23385.0,
      "step": 11
    },
    {
      "entropy": 1.421536619013006,
      "epoch": 4.0,
      "grad_norm": 2.197089433670044,
      "learning_rate": 8.865052266813686e-06,
      "loss": 0.9174,
      "mean_token_accuracy": 0.8264588605273854,
      "num_tokens": 25272.0,
      "step": 12
    },
    {
      "entropy": 1.4514975994825363,
      "epoch": 4.372093023255814,
      "grad_norm": 1.8561780452728271,
      "learning_rate": 8.535533905932739e-06,
      "loss": 0.8801,
      "mean_token_accuracy": 0.8231428451836109,
      "num_tokens": 28245.0,
      "step": 13
    },
    {
      "entropy": 1.5802567154169083,
      "epoch": 4.7441860465116275,
      "grad_norm": 2.3061466217041016,
      "learning_rate": 8.171966420818227e-06,
      "loss": 0.8429,
      "mean_token_accuracy": 0.8271992728114128,
      "num_tokens": 30283.0,
      "step": 14
    },
    {
      "entropy": 1.6152980002489956,
      "epoch": 5.0,
      "grad_norm": 2.1123287677764893,
      "learning_rate": 7.777851165098012e-06,
      "loss": 0.7475,
      "mean_token_accuracy": 0.8613714250651273,
      "num_tokens": 31590.0,
      "step": 15
    },
    {
      "entropy": 1.6368180140852928,
      "epoch": 5.372093023255814,
      "grad_norm": 2.4998180866241455,
      "learning_rate": 7.3569836841299905e-06,
      "loss": 0.8752,
      "mean_token_accuracy": 0.8332529291510582,
      "num_tokens": 33360.0,
      "step": 16
    },
    {
      "entropy": 1.4183942936360836,
      "epoch": 5.7441860465116275,
      "grad_norm": 1.5721269845962524,
      "learning_rate": 6.913417161825449e-06,
      "loss": 0.7462,
      "mean_token_accuracy": 0.849718414247036,
      "num_tokens": 36519.0,
      "step": 17
    },
    {
      "entropy": 1.5972948507829146,
      "epoch": 6.0,
      "grad_norm": 2.405885696411133,
      "learning_rate": 6.451423386272312e-06,
      "loss": 0.805,
      "mean_token_accuracy": 0.8347415707328103,
      "num_tokens": 37908.0,
      "step": 18
    },
    {
      "entropy": 1.4845862239599228,
      "epoch": 6.372093023255814,
      "grad_norm": 1.828986406326294,
      "learning_rate": 5.975451610080643e-06,
      "loss": 0.7339,
      "mean_token_accuracy": 0.8368060104548931,
      "num_tokens": 40619.0,
      "step": 19
    },
    {
      "entropy": 1.553262583911419,
      "epoch": 6.7441860465116275,
      "grad_norm": 2.00793194770813,
      "learning_rate": 5.490085701647805e-06,
      "loss": 0.7745,
      "mean_token_accuracy": 0.8567813038825989,
      "num_tokens": 43042.0,
      "step": 20
    },
    {
      "entropy": 1.6345414085821672,
      "epoch": 7.0,
      "grad_norm": 2.2980940341949463,
      "learning_rate": 5e-06,
      "loss": 0.7454,
      "mean_token_accuracy": 0.8426129384474321,
      "num_tokens": 44226.0,
      "step": 21
    },
    {
      "entropy": 1.5351210460066795,
      "epoch": 7.372093023255814,
      "grad_norm": 1.7042779922485352,
      "learning_rate": 4.509914298352197e-06,
      "loss": 0.6596,
      "mean_token_accuracy": 0.8864378668367863,
      "num_tokens": 46461.0,
      "step": 22
    },
    {
      "entropy": 1.5389362946152687,
      "epoch": 7.7441860465116275,
      "grad_norm": 1.642480492591858,
      "learning_rate": 4.02454838991936e-06,
      "loss": 0.7271,
      "mean_token_accuracy": 0.8503848239779472,
      "num_tokens": 49072.0,
      "step": 23
    },
    {
      "entropy": 1.588984413580461,
      "epoch": 8.0,
      "grad_norm": 2.4330005645751953,
      "learning_rate": 3.5485766137276894e-06,
      "loss": 0.8016,
      "mean_token_accuracy": 0.8205744353207675,
      "num_tokens": 50544.0,
      "step": 24
    },
    {
      "entropy": 1.4498572759330273,
      "epoch": 8.372093023255815,
      "grad_norm": 1.9567660093307495,
      "learning_rate": 3.0865828381745515e-06,
      "loss": 0.7527,
      "mean_token_accuracy": 0.831371396780014,
      "num_tokens": 53147.0,
      "step": 25
    },
    {
      "entropy": 1.607713084667921,
      "epoch": 8.744186046511627,
      "grad_norm": 1.8003907203674316,
      "learning_rate": 2.6430163158700116e-06,
      "loss": 0.6927,
      "mean_token_accuracy": 0.8694727867841721,
      "num_tokens": 55190.0,
      "step": 26
    },
    {
      "entropy": 1.6167547269300981,
      "epoch": 9.0,
      "grad_norm": 1.6587848663330078,
      "learning_rate": 2.2221488349019903e-06,
      "loss": 0.6207,
      "mean_token_accuracy": 0.8961980397051031,
      "num_tokens": 56862.0,
      "step": 27
    },
    {
      "entropy": 1.5565419383347034,
      "epoch": 9.372093023255815,
      "grad_norm": 1.551279067993164,
      "learning_rate": 1.8280335791817733e-06,
      "loss": 0.6368,
      "mean_token_accuracy": 0.8657520264387131,
      "num_tokens": 59543.0,
      "step": 28
    },
    {
      "entropy": 1.5979384370148182,
      "epoch": 9.744186046511627,
      "grad_norm": 2.044733762741089,
      "learning_rate": 1.4644660940672628e-06,
      "loss": 0.7106,
      "mean_token_accuracy": 0.8532840460538864,
      "num_tokens": 61573.0,
      "step": 29
    },
    {
      "entropy": 1.4783042398366062,
      "epoch": 10.0,
      "grad_norm": 1.9428529739379883,
      "learning_rate": 1.134947733186315e-06,
      "loss": 0.7424,
      "mean_token_accuracy": 0.8778879534114491,
      "num_tokens": 63180.0,
      "step": 30
    },
    {
      "entropy": 1.5532260611653328,
      "epoch": 10.372093023255815,
      "grad_norm": 2.087916612625122,
      "learning_rate": 8.426519384872733e-07,
      "loss": 0.7754,
      "mean_token_accuracy": 0.8664120212197304,
      "num_tokens": 65326.0,
      "step": 31
    },
    {
      "entropy": 1.4917264878749847,
      "epoch": 10.744186046511627,
      "grad_norm": 1.5266973972320557,
      "learning_rate": 5.903936782582253e-07,
      "loss": 0.6108,
      "mean_token_accuracy": 0.8663139119744301,
      "num_tokens": 67813.0,
      "step": 32
    },
    {
      "entropy": 1.6349257230758667,
      "epoch": 11.0,
      "grad_norm": 1.5661303997039795,
      "learning_rate": 3.8060233744356634e-07,
      "loss": 0.6689,
      "mean_token_accuracy": 0.8604073470289056,
      "num_tokens": 69498.0,
      "step": 33
    },
    {
      "entropy": 1.5997699834406376,
      "epoch": 11.372093023255815,
      "grad_norm": 1.9380265474319458,
      "learning_rate": 2.152983213389559e-07,
      "loss": 0.7009,
      "mean_token_accuracy": 0.8598572909832001,
      "num_tokens": 71308.0,
      "step": 34
    },
    {
      "entropy": 1.6602987572550774,
      "epoch": 11.744186046511627,
      "grad_norm": 1.8492374420166016,
      "learning_rate": 9.607359798384785e-08,
      "loss": 0.6784,
      "mean_token_accuracy": 0.8869365006685257,
      "num_tokens": 73415.0,
      "step": 35
    },
    {
      "entropy": 1.325790985064073,
      "epoch": 12.0,
      "grad_norm": 1.6550756692886353,
      "learning_rate": 2.4076366639015914e-08,
      "loss": 0.6572,
      "mean_token_accuracy": 0.8415168198672208,
      "num_tokens": 75816.0,
      "step": 36
    }
  ],
  "logging_steps": 1,
  "max_steps": 36,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 12,
  "save_steps": 1,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1287767051550720.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
